{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import tensorflow as tf\r\n",
    "import tensorflow.keras as keras\r\n",
    "import pandas as pd   \r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "imdb_reviews = pd.read_csv(\"imdb_reviews.csv\")\r\n",
    "test_reviews = pd.read_csv(\"test_reviews.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "imdb_reviews.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START this film was just brilliant casting lo...  positive\n",
       "1  <START big hair big boobs bad music and a gian...  negative\n",
       "2  <START this has to be one of the worst films o...  negative\n",
       "3  <START the <UNK> <UNK> at storytelling the tra...  positive\n",
       "4  <START worst mistake of my life br br i picked...  negative"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START this film was just brilliant casting lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START big hair big boobs bad music and a gian...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START this has to be one of the worst films o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START the &lt;UNK&gt; &lt;UNK&gt; at storytelling the tra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START worst mistake of my life br br i picked...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_reviews.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START please give this one a miss br br <UNK>...  negative\n",
       "1  <START this film requires a lot of patience be...  positive\n",
       "2  <START many animation buffs consider <UNK> <UN...  positive\n",
       "3  <START i generally love this type of movie how...  negative\n",
       "4  <START like some other people wrote i'm a die ...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START please give this one a miss br br &lt;UNK&gt;...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START this film requires a lot of patience be...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START many animation buffs consider &lt;UNK&gt; &lt;UN...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START i generally love this type of movie how...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START like some other people wrote i'm a die ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can not pass the string data to our model directly, so we need to transform the string data into integer format.For this we can map each distinct word as a distinct integer for eg.{'this':14 , 'the':1}.We already have a file that contains the mapping from words to integers so we are going to load that file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "word_index = pd.read_csv(\"word_indexes.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "word_index.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Words  Indexes\n",
       "0  tsukino    52009\n",
       "1  nunnery    52010\n",
       "2    sonja    16819\n",
       "3     vani    63954\n",
       "4    woods     1411"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woods</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " convert the word_index dataframe into a python dictionary so that we can use it for converting our reviews from string to integer format."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#Converting to dictionary\r\n",
    "word_index = dict(zip(word_index.Words, word_index.Indexes))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "word_index[\"<PAD>\"]=0\r\n",
    "word_index[\"<START\"]=1\r\n",
    "word_index[\"<UNK>\"]=2\r\n",
    "word_index[\"<UNUSED>\"]=3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def review_encoder(text):\r\n",
    "  arr=[word_index[word] for word in text]\r\n",
    "  return arr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#split the reviews from their corresponding sentiments\r\n",
    "train_data,train_labels=imdb_reviews['Reviews'],imdb_reviews['Sentiment']\r\n",
    "test_data, test_labels=test_reviews['Reviews'],test_reviews['Sentiment']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "train_data=train_data.apply(lambda review:review.split())\r\n",
    "test_data=test_data.apply(lambda review:review.split())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train_data[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['<START',\n",
       " 'this',\n",
       " 'film',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'casting',\n",
       " 'location',\n",
       " 'scenery',\n",
       " 'story',\n",
       " 'direction',\n",
       " \"everyone's\",\n",
       " 'really',\n",
       " 'suited',\n",
       " 'the',\n",
       " 'part',\n",
       " 'they',\n",
       " 'played',\n",
       " 'and',\n",
       " 'you',\n",
       " 'could',\n",
       " 'just',\n",
       " 'imagine',\n",
       " 'being',\n",
       " 'there',\n",
       " 'robert',\n",
       " '<UNK>',\n",
       " 'is',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'actor',\n",
       " 'and',\n",
       " 'now',\n",
       " 'the',\n",
       " 'same',\n",
       " 'being',\n",
       " 'director',\n",
       " '<UNK>',\n",
       " 'father',\n",
       " 'came',\n",
       " 'from',\n",
       " 'the',\n",
       " 'same',\n",
       " 'scottish',\n",
       " 'island',\n",
       " 'as',\n",
       " 'myself',\n",
       " 'so',\n",
       " 'i',\n",
       " 'loved',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'there',\n",
       " 'was',\n",
       " 'a',\n",
       " 'real',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'this',\n",
       " 'film',\n",
       " 'the',\n",
       " 'witty',\n",
       " 'remarks',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'film',\n",
       " 'were',\n",
       " 'great',\n",
       " 'it',\n",
       " 'was',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'so',\n",
       " 'much',\n",
       " 'that',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'the',\n",
       " 'film',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'it',\n",
       " 'was',\n",
       " 'released',\n",
       " 'for',\n",
       " '<UNK>',\n",
       " 'and',\n",
       " 'would',\n",
       " 'recommend',\n",
       " 'it',\n",
       " 'to',\n",
       " 'everyone',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fly',\n",
       " 'fishing',\n",
       " 'was',\n",
       " 'amazing',\n",
       " 'really',\n",
       " 'cried',\n",
       " 'at',\n",
       " 'the',\n",
       " 'end',\n",
       " 'it',\n",
       " 'was',\n",
       " 'so',\n",
       " 'sad',\n",
       " 'and',\n",
       " 'you',\n",
       " 'know',\n",
       " 'what',\n",
       " 'they',\n",
       " 'say',\n",
       " 'if',\n",
       " 'you',\n",
       " 'cry',\n",
       " 'at',\n",
       " 'a',\n",
       " 'film',\n",
       " 'it',\n",
       " 'must',\n",
       " 'have',\n",
       " 'been',\n",
       " 'good',\n",
       " 'and',\n",
       " 'this',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'also',\n",
       " '<UNK>',\n",
       " 'to',\n",
       " 'the',\n",
       " 'two',\n",
       " 'little',\n",
       " \"boy's\",\n",
       " 'that',\n",
       " 'played',\n",
       " 'the',\n",
       " '<UNK>',\n",
       " 'of',\n",
       " 'norman',\n",
       " 'and',\n",
       " 'paul',\n",
       " 'they',\n",
       " 'were',\n",
       " 'just',\n",
       " 'brilliant',\n",
       " 'children',\n",
       " 'are',\n",
       " 'often',\n",
       " 'left',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " '<UNK>',\n",
       " 'list',\n",
       " 'i',\n",
       " 'think',\n",
       " 'because',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'play',\n",
       " 'them',\n",
       " 'all',\n",
       " 'grown',\n",
       " 'up',\n",
       " 'are',\n",
       " 'such',\n",
       " 'a',\n",
       " 'big',\n",
       " 'profile',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'but',\n",
       " 'these',\n",
       " 'children',\n",
       " 'are',\n",
       " 'amazing',\n",
       " 'and',\n",
       " 'should',\n",
       " 'be',\n",
       " 'praised',\n",
       " 'for',\n",
       " 'what',\n",
       " 'they',\n",
       " 'have',\n",
       " 'done',\n",
       " \"don't\",\n",
       " 'you',\n",
       " 'think',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'story',\n",
       " 'was',\n",
       " 'so',\n",
       " 'lovely',\n",
       " 'because',\n",
       " 'it',\n",
       " 'was',\n",
       " 'true',\n",
       " 'and',\n",
       " 'was',\n",
       " \"someone's\",\n",
       " 'life',\n",
       " 'after',\n",
       " 'all',\n",
       " 'that',\n",
       " 'was',\n",
       " 'shared',\n",
       " 'with',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#we have tokenized the reviews now we can apply the review_encoder function to each review and transform the reviews into integer format.\r\n",
    "train_data=train_data.apply(review_encoder)\r\n",
    "test_data=test_data.apply(review_encoder)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "train_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, ...\n",
       "1    [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463,...\n",
       "2    [1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5...\n",
       "3    [1, 4, 2, 2, 33, 2804, 4, 2040, 432, 111, 153,...\n",
       "4    [1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 1...\n",
       "Name: Reviews, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#We also need to encode the sentiments and we are labeling the positive sentiment as 1 and negative sentiment as 0\r\n",
    "def encode_sentiments(x):\r\n",
    "  if x=='positive':\r\n",
    "    return 1\r\n",
    "  else:\r\n",
    "    return 0\r\n",
    "\r\n",
    "train_labels=train_labels.apply(encode_sentiments)\r\n",
    "test_labels=test_labels.apply(encode_sentiments)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before giving the review as an input to the model we need to perform following preprocessing steps:\r\n",
    "\r\n",
    "The length of each review should be made equal for the model to be working correctly.\r\n",
    "\r\n",
    "We have chosen the length of each review to be 500.\r\n",
    "\r\n",
    "If the review is longer than 500 words we are going to cut the extra part of the review.\r\n",
    "\r\n",
    "If the review is contains less than 500 words we are going to pad the review with zeros to increase its length to 500."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value = word_index [\"<PAD>\"], padding='post', maxlen=500)\r\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value = word_index [\"<PAD>\"], padding='post', maxlen=500)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our model is a neural network and it consits of the following layers :\r\n",
    "\r\n",
    "one word embedding layer which creates word embeddings of length 16 from integer encoded review.\r\n",
    "\r\n",
    "second layer is global average pooling layer which is used to prevent overfitting by reducing the number of parameters.\r\n",
    "\r\n",
    "then a dense layer which has 16 hidden units and uses relu as activation function\r\n",
    "\r\n",
    "the final layer is the output layer which uses sigmoid as activation function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "model=keras.Sequential([keras.layers.Embedding(10000,16,input_length=500),\r\n",
    "                        keras.layers.GlobalAveragePooling1D(),\r\n",
    "                        keras.layers.Dense(16,activation='relu'),\r\n",
    "                        keras.layers.Dense(1,activation='sigmoid')])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\r\n",
    "\"\"\"\r\n",
    "Adam is used as optimization function for our model.\r\n",
    "\r\n",
    "Binary cross entropy loss function is used as loss function for the model.\r\n",
    "\r\n",
    "Accuracy is used as the metric for evaluating the model.\r\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nAdam is used as optimization function for our model.\\n\\nBinary cross entropy loss function is used as loss function for the model.\\n\\nAccuracy is used as the metric for evaluating the model.\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "#training the model\r\n",
    "history=model.fit(train_data,train_labels,epochs=30,batch_size=512,validation_data=(test_data,test_labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 1s 28ms/step - loss: 0.6917 - accuracy: 0.5922 - val_loss: 0.6895 - val_accuracy: 0.7273\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.6842 - accuracy: 0.7138 - val_loss: 0.6776 - val_accuracy: 0.7348\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.6635 - accuracy: 0.7386 - val_loss: 0.6503 - val_accuracy: 0.7102\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.6246 - accuracy: 0.7682 - val_loss: 0.6065 - val_accuracy: 0.7794\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.5712 - accuracy: 0.8078 - val_loss: 0.5555 - val_accuracy: 0.7991\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.5127 - accuracy: 0.8310 - val_loss: 0.5008 - val_accuracy: 0.8263\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.4555 - accuracy: 0.8532 - val_loss: 0.4535 - val_accuracy: 0.8408\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.4071 - accuracy: 0.8664 - val_loss: 0.4155 - val_accuracy: 0.8519\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.3680 - accuracy: 0.8776 - val_loss: 0.3857 - val_accuracy: 0.8594\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.3372 - accuracy: 0.8856 - val_loss: 0.3634 - val_accuracy: 0.8651\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.3128 - accuracy: 0.8928 - val_loss: 0.3477 - val_accuracy: 0.8674\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2929 - accuracy: 0.8982 - val_loss: 0.3329 - val_accuracy: 0.8734\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.2761 - accuracy: 0.9038 - val_loss: 0.3228 - val_accuracy: 0.8743\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.2618 - accuracy: 0.9084 - val_loss: 0.3167 - val_accuracy: 0.8746\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2495 - accuracy: 0.9130 - val_loss: 0.3078 - val_accuracy: 0.8787\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2376 - accuracy: 0.9179 - val_loss: 0.3025 - val_accuracy: 0.8801\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2278 - accuracy: 0.9210 - val_loss: 0.2972 - val_accuracy: 0.8822\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2191 - accuracy: 0.9248 - val_loss: 0.2958 - val_accuracy: 0.8822\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.2117 - accuracy: 0.9270 - val_loss: 0.2925 - val_accuracy: 0.8830\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.2033 - accuracy: 0.9297 - val_loss: 0.2899 - val_accuracy: 0.8842\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.1959 - accuracy: 0.9326 - val_loss: 0.2880 - val_accuracy: 0.8859\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1891 - accuracy: 0.9352 - val_loss: 0.2877 - val_accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1836 - accuracy: 0.9372 - val_loss: 0.2905 - val_accuracy: 0.8841\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1781 - accuracy: 0.9393 - val_loss: 0.2851 - val_accuracy: 0.8861\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1720 - accuracy: 0.9423 - val_loss: 0.2853 - val_accuracy: 0.8862\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1671 - accuracy: 0.9441 - val_loss: 0.2853 - val_accuracy: 0.8862\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1622 - accuracy: 0.9462 - val_loss: 0.2881 - val_accuracy: 0.8859\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.1577 - accuracy: 0.9476 - val_loss: 0.2881 - val_accuracy: 0.8859\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1531 - accuracy: 0.9495 - val_loss: 0.2915 - val_accuracy: 0.8854\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1500 - accuracy: 0.9496 - val_loss: 0.2904 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "loss,accuracy=model.evaluate(test_data,test_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "782/782 [==============================] - 0s 593us/step - loss: 0.2904 - accuracy: 0.8862\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "index = np.random.randint(1, 1000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "user_review = test_reviews.loc[index]\r\n",
    "print(user_review)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reviews      <START the plot is simple an american couple i...\n",
      "Sentiment                                             negative\n",
      "Name: 695, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see the sentiment for the above review is positive, now we are going to take the integer format of this particular review which we already have in our preprocessed test data and then give it as an input to our model to check the prediction of our model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "user_review=test_data[index]\r\n",
    "user_review= np.array([user_review])\r\n",
    "if (model.predict(user_review) > 0.5).astype('int32'):\r\n",
    "    print(\"Positive sentiment\")\r\n",
    "else:\r\n",
    "    print(\"Negative sentiment\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Negative sentiment\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "9ec957caba7ae6ccc97a7fb0804bf14cbdb1f70a4904cd45a06dd27fe16a3b19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}